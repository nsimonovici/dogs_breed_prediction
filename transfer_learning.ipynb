{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "from shutil import copyfile, rmtree\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from keras.layers import Flatten, Dense, Dropout, BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras.preprocessing.image import load_img, img_to_array, ImageDataGenerator\n",
    "from keras import optimizers\n",
    "import scipy.io\n",
    "from PIL import Image\n",
    "from sklearn import metrics, preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dynamic_std_print(string_to_print):\n",
    "    \"\"\"\n",
    "    Printing string on standard output and refreshing output line\n",
    "    \"\"\"\n",
    "    sys.stdout.write('\\r')\n",
    "    sys.stdout.write(string_to_print)\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set folder delimiter\n",
    "if os.name == 'posix':\n",
    "    fd = \"/\"\n",
    "else:\n",
    "    fd = \"\\\\\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Get data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gather our files paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get local path\n",
    "local_path = os.getcwd()\n",
    "pictures_path = local_path + '/data/images/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List images folders\n",
    "breeds_folders = [local_path + \"/data/images/\" + file_name for file_name in os.listdir(local_path + \"/data/images\") if os.path.isdir(local_path + \"/data/images/\" + file_name)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List breeds id and name\n",
    "breeds_id = [breed_path.split(\"/\")[-1].split(\"-\")[0] for breed_path in breeds_folders]\n",
    "breeds_name = [\"-\".join(breed_path.split(\"/\")[-1].split(\"-\")[1:]) for breed_path in breeds_folders]\n",
    "breed_dict = dict(zip(breeds_id, breeds_name))\n",
    "reverse_breed_dict = dict(zip(breeds_name, breeds_id))\n",
    "n_breeds = len(breeds_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use train and test sets provided with data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mat = scipy.io.loadmat(local_path + '/data/lists/train_list.mat')\n",
    "test_mat = scipy.io.loadmat(local_path + '/data/lists/test_list.mat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert matlab matrix to pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# For train set\n",
    "train_df = pd.DataFrame(train_mat['labels'], columns=['label'])\n",
    "train_df['file'] = [str(file_name[0].tolist()[0]) for file_name in train_mat['file_list']]\n",
    "train_df['breed_id'] = train_df.file.apply(lambda x: x.split(\"/\")[0].split(\"-\")[0])\n",
    "train_df['breed_name'] = train_df.breed_id.apply(lambda x: breed_dict[x])\n",
    "train_df.label = train_df.label.apply(lambda x: x - 1)\n",
    "\n",
    "# For test set\n",
    "test_df = pd.DataFrame(test_mat['labels'], columns=['label'])\n",
    "test_df['file'] = [str(file_name[0].tolist()[0]) for file_name in test_mat['file_list']]\n",
    "test_df['breed_id'] = test_df.file.apply(lambda x: x.split(\"/\")[0].split(\"-\")[0])\n",
    "test_df['breed_name'] = test_df.breed_id.apply(lambda x: breed_dict[x])\n",
    "test_df.label = test_df.label.apply(lambda x: x - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get label-names dict\n",
    "breed_labels_df = train_df.loc[:, ['label', 'breed_name']].drop_duplicates()\n",
    "breed_label_dict = dict(zip(breed_labels_df.label.values, breed_labels_df.breed_name.values))\n",
    "label_breed_dict = dict([[v,k] for k,v in breed_label_dict.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>file</th>\n",
       "      <th>breed_id</th>\n",
       "      <th>breed_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10701</th>\n",
       "      <td>107</td>\n",
       "      <td>n02112018-Pomeranian/n02112018_9376.jpg</td>\n",
       "      <td>n02112018</td>\n",
       "      <td>Pomeranian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3552</th>\n",
       "      <td>35</td>\n",
       "      <td>n02094258-Norwich_terrier/n02094258_905.jpg</td>\n",
       "      <td>n02094258</td>\n",
       "      <td>Norwich_terrier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6633</th>\n",
       "      <td>66</td>\n",
       "      <td>n02102040-English_springer/n02102040_3335.jpg</td>\n",
       "      <td>n02102040</td>\n",
       "      <td>English_springer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2169</th>\n",
       "      <td>21</td>\n",
       "      <td>n02091134-whippet/n02091134_11775.jpg</td>\n",
       "      <td>n02091134</td>\n",
       "      <td>whippet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6948</th>\n",
       "      <td>69</td>\n",
       "      <td>n02102480-Sussex_spaniel/n02102480_5805.jpg</td>\n",
       "      <td>n02102480</td>\n",
       "      <td>Sussex_spaniel</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                                           file   breed_id  \\\n",
       "10701    107        n02112018-Pomeranian/n02112018_9376.jpg  n02112018   \n",
       "3552      35    n02094258-Norwich_terrier/n02094258_905.jpg  n02094258   \n",
       "6633      66  n02102040-English_springer/n02102040_3335.jpg  n02102040   \n",
       "2169      21          n02091134-whippet/n02091134_11775.jpg  n02091134   \n",
       "6948      69    n02102480-Sussex_spaniel/n02102480_5805.jpg  n02102480   \n",
       "\n",
       "             breed_name  \n",
       "10701        Pomeranian  \n",
       "3552    Norwich_terrier  \n",
       "6633   English_springer  \n",
       "2169            whippet  \n",
       "6948     Sussex_spaniel  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy files to train and test folders for CNN training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Copy train files to train folder\n",
    "# for file in train_df.file.values:\n",
    "#     folder = file.split(\"/\")[0]\n",
    "#     file_name = file.split(\"/\")[-1]\n",
    "#     if not os.path.exists(local_path + '\\\\data\\\\train\\\\' + folder):\n",
    "#         os.mkdir(local_path + '\\\\data\\\\train\\\\' + folder)\n",
    "#         dynamic_std_print(\"Creating folder {}                  \".format(folder))\n",
    "#     copyfile(pictures_path + file, local_path + '\\\\data\\\\train\\\\' + folder + '\\\\' + file_name)\n",
    "    \n",
    "# # Copy test files to test folder\n",
    "# for file in test_df.file.values:\n",
    "#     folder = file.split(\"/\")[0]\n",
    "#     file_name = file.split(\"/\")[-1]\n",
    "#     if not os.path.exists(local_path + '\\\\data\\\\test\\\\' + folder):\n",
    "#         os.mkdir(local_path + '\\\\data\\\\test\\\\' + folder)\n",
    "#         dynamic_std_print(\"Creating folder {}                  \".format(folder))\n",
    "#     copyfile(pictures_path + file, local_path + '\\\\data\\\\test\\\\' + folder + '\\\\' + file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Copy files to small train and test folders for CNN training (few files for debuging purposes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_name = \"cnn2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove folders content\n",
    "folders = [local_path + fd + 'data' + fd + folder_name + fd + 'train' + fd,\n",
    "           local_path + fd + 'data' + fd + folder_name + fd + 'test' + fd + 'test_folder',\n",
    "           local_path + fd + 'data' + fd + folder_name + fd + 'valid' + fd,\n",
    "           local_path + fd + 'data' + fd + folder_name + fd + 'test_folder' + fd]\n",
    "for folder in folders:\n",
    "    for the_file in os.listdir(folder):\n",
    "        file_path = os.path.join(folder, the_file)\n",
    "        try:\n",
    "            if os.path.isfile(file_path):\n",
    "                os.unlink(file_path)\n",
    "            elif os.path.isdir(file_path):\n",
    "                rmtree(file_path)\n",
    "        except Exception as e:\n",
    "            print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set list of breeds matching histograms + kmeans method for comparison purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_labels = ['Scotch_terrier', 'Eskimo_dog', 'Rhodesian_ridgeback', 'Great_Dane', 'French_bulldog']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract specific pictures for CNN usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating folder n02108915-French_bulldog                                  "
     ]
    }
   ],
   "source": [
    "# Copy train and valid  files to train and valid folders\n",
    "# Get n pic for each label\n",
    "n_train = 90\n",
    "n_valid = 10\n",
    "n_test = 30\n",
    "\n",
    "for label_name in list_labels: # train_df.label.unique():\n",
    "    # Convert dog's name to label number\n",
    "    label = label_breed_dict[label_name]\n",
    "    # Slice train DF to specified label\n",
    "    label_df = train_df[train_df.label == label].sample(n_train + n_valid, random_state=0)\n",
    "    \n",
    "    # Copy training files\n",
    "    for file in label_df.file.values[:n_train]:\n",
    "        folder = file.split(\"/\")[0]\n",
    "        file_name = file.split(\"/\")[-1]\n",
    "        if not os.path.exists(local_path + fd + 'data' + fd + folder_name + fd + 'train' + fd + folder):\n",
    "            os.mkdir(local_path + fd + 'data' + fd + folder_name + fd + 'train' + fd + folder)\n",
    "            dynamic_std_print(\"Creating folder {}                             \".format(folder))\n",
    "        copyfile(pictures_path + file, local_path + fd + 'data' + fd + folder_name + fd + 'train' + fd + folder + fd + '' + file_name)\n",
    "        \n",
    "    # Copy validation files        \n",
    "    for file in label_df.file.values[n_train:]:\n",
    "        folder = file.split(\"/\")[0]\n",
    "        file_name = file.split(\"/\")[-1]\n",
    "        if not os.path.exists(local_path + fd + 'data' + fd + folder_name + fd + 'valid' + fd + folder):\n",
    "            os.mkdir(local_path + fd + 'data' + fd + folder_name + fd + 'valid' + fd + folder)\n",
    "            dynamic_std_print(\"Creating folder {}                             \".format(folder))\n",
    "        copyfile(pictures_path + file, local_path + fd + 'data' + fd + folder_name + fd + 'valid' + fd + folder + fd + '' + file_name)\n",
    "\n",
    "    label_df = test_df[test_df.label == label].sample(n_test, random_state=0)\n",
    "    # Copy testing files        \n",
    "    for file in label_df.file.values:\n",
    "        folder = file.split(\"/\")[0]\n",
    "        file_name = file.split(\"/\")[-1]\n",
    "        if not os.path.exists(local_path + fd + 'data' + fd + folder_name + fd + 'test_folder' + fd + folder):\n",
    "            os.mkdir(local_path + fd + 'data' + fd + folder_name + fd + 'test_folder' + fd + folder)\n",
    "            dynamic_std_print(\"Creating folder {}                             \".format(folder))\n",
    "        copyfile(pictures_path + file, local_path + fd + 'data' + fd + folder_name + fd + 'test_folder' + fd + folder + fd + '' + file_name)\n",
    "\n",
    "# Copy test files to test folder\n",
    "# Get m pic for each label\n",
    "target_names = []\n",
    "for label_name in list_labels: #train_df.label.unique():\n",
    "    # Convert dog's name to label number\n",
    "    label = label_breed_dict[label_name]\n",
    "    # Slice test DF to specified label\n",
    "    label_df = test_df[test_df.label == label].sample(n_test, random_state=0)\n",
    "    for file in label_df.file.values:\n",
    "        folder = file.split(\"/\")[0]\n",
    "        file_name = file.split(\"/\")[-1]\n",
    "        file_breed = file_name.split(\"_\")[0]\n",
    "        target_names.append(file_breed)\n",
    "        copyfile(pictures_path + file, local_path + fd + 'data' + fd + folder_name + fd + 'test' + fd + 'test_folder' + fd + file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build new labels list from sub-folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the breeds in the training folder of our CNN : \n",
      " ['Rhodesian_ridgeback', 'Scotch_terrier', 'French_bulldog', 'Great_Dane', 'Eskimo_dog']\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'n_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-5436265d2bdc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mtest_pictures_breeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mtest_pictures_breeds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnn_targets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'n_test' is not defined"
     ]
    }
   ],
   "source": [
    "cnn_targets = []\n",
    "for subfold in os.listdir(local_path + fd + 'data' + fd + folder_name + fd + 'train'):\n",
    "    cnn_targets.append(subfold.split(\"-\")[1])\n",
    "print(\"Here are the breeds in the training folder of our CNN : \\n\", cnn_targets)\n",
    "# Create test pictures list\n",
    "test_pictures_breeds = []\n",
    "for i in range(len(list_labels)):\n",
    "    for j in range(n_test):\n",
    "        test_pictures_breeds.append(cnn_targets[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Associate local labels to those breeds folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the encoded breeds in the training folder of our CNN : \n",
      " [3 4 1 2 0]\n"
     ]
    }
   ],
   "source": [
    "# Create label encoder\n",
    "subfold_enc = preprocessing.LabelEncoder()\n",
    "# Fit encoder on breeds names\n",
    "subfold_enc.fit(cnn_targets)\n",
    "# Convert breeds names\n",
    "cnn_targets_labels = subfold_enc.transform(cnn_targets)\n",
    "print(\"Here are the encoded breeds in the training folder of our CNN : \\n\", cnn_targets_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Modify Conventional Neural Network for Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use Keras VGG-16 CNN already trained on ImageNet database in order to predict our dogs breeds.\n",
    "\n",
    "Steps are as follow :\n",
    "- 1) Call the pre-trained VGG-16 CNN\n",
    "- 2) Apply partial fine-tuning because we don't have much data (20e3) and they are dogs only, unlike ImageNet database\n",
    "- 3) Run modified model for dogs classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare pictures batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 450 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "train_batch_size = 90\n",
    "# Initialise data generator\n",
    "train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "# Fit generator from train folder. Folder must contains one sub-directory by class\n",
    "train_generator = train_datagen.flow_from_directory(local_path + '/data/' + folder_name + '/train',\n",
    "                                                    target_size=(224,224),\n",
    "                                                    color_mode='rgb',\n",
    "                                                    batch_size=train_batch_size,\n",
    "                                                    class_mode='categorical',\n",
    "                                                    shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 50 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "valid_batch_size = 10\n",
    "# Initialise data generator\n",
    "valid_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "# Fit generator from train folder. Folder must contains one sub-directory by class\n",
    "valid_generator = valid_datagen.flow_from_directory(local_path + '/data/' + folder_name + '/valid',\n",
    "                                                    target_size=(224,224),\n",
    "                                                    color_mode='rgb',\n",
    "                                                    batch_size=valid_batch_size,\n",
    "                                                    class_mode='categorical',\n",
    "                                                    shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test batch : from test sub-folders with anotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 150 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "test_batch_size = 30\n",
    "# Initialise data generator\n",
    "test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "# Fit generator from train folder. Folder must contains one sub-directory by class\n",
    "test_generator = test_datagen.flow_from_directory(local_path + '/data/' + folder_name + '/test_folder',\n",
    "                                                  target_size=(224,224),\n",
    "                                                  color_mode='rgb',\n",
    "                                                  batch_size=test_batch_size,\n",
    "                                                  class_mode='categorical',\n",
    "                                                  shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test batch : from a unique test sub-folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 150 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "test_batch_size = 10\n",
    "# Initialise data generator\n",
    "test_datagen_unique = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "# Fit generator from train folder. Folder must contains one sub-directory by class\n",
    "test_gen_unique = test_datagen_unique.flow_from_directory(local_path + '/data/' + folder_name + '/test',\n",
    "                                                         target_size=(224,224),\n",
    "                                                         color_mode='rgb',\n",
    "                                                         batch_size=test_batch_size,\n",
    "                                                         class_mode='categorical',\n",
    "                                                         shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Test on generator content\n",
    "# count=1\n",
    "# for item in test_generator:\n",
    "#     plt.imshow(item[0][0])\n",
    "#     break\n",
    "# #     print(count)\n",
    "# #     save_test_item = item\n",
    "# #     break\n",
    "# #     count+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prep model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load VGG-16 pre-trained on ImageNet without the fully-connected layers\n",
    "model = VGG16(weights=\"imagenet\", include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Get output of this model\n",
    "x = model.output\n",
    "\n",
    "# ???\n",
    "x = model.output\n",
    "x = Flatten()(x)\n",
    "x = Dropout(0.4)(x)\n",
    "# let's add two fully-connected layer\n",
    "x = Dense(2048, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.4)(x)\n",
    "x = Dense(2048, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.2)(x)\n",
    "\n",
    "# Add new fully-connected layer for N classes classification\n",
    "predictions = Dense(5, activation='softmax')(x)\n",
    "\n",
    "# Define new model\n",
    "new_model = Model(inputs=model.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not train 5 first layers (the lowest)\n",
    "for layer in new_model.layers[:5]:\n",
    "   layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "new_model.compile(loss=\"categorical_crossentropy\", optimizer=optimizers.SGD(lr=0.0001, momentum=0.9), metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's in our model so far ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2048)              51382272  \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 2048)              8192      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2048)              4196352   \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 2048)              8192      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 5)                 10245     \n",
      "=================================================================\n",
      "Total params: 70,319,941\n",
      "Trainable params: 70,199,173\n",
      "Non-trainable params: 120,768\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " 3/10 [========>.....................] - ETA: 8:28 - loss: 0.0320 - acc: 0.9926"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-350723e90ca7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m                                          \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                                          \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m                                          verbose=1)\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1424\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1425\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1426\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1428\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    189\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    190\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1218\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1220\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1221\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1222\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2659\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2660\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2661\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2662\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2663\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2629\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2630\u001b[0m                                 session)\n\u001b[0;32m-> 2631\u001b[0;31m         \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2632\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1449\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_with_new_api\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1450\u001b[0m           return tf_session.TF_SessionRunCallable(\n\u001b[0;32m-> 1451\u001b[0;31m               self._session._session, self._handle, args, status, None)\n\u001b[0m\u001b[1;32m   1452\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1453\u001b[0m           return tf_session.TF_DeprecatedSessionRunCallable(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train on training generator\n",
    "n_epochs = 100\n",
    "model_complete = new_model.fit_generator(train_generator,\n",
    "                                         steps_per_epoch=10,\n",
    "                                         epochs=n_epochs,\n",
    "                                         validation_data=valid_generator,\n",
    "                                         validation_steps=10,\n",
    "                                         verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Epochs accuracy evolution ploting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training & validation accuracy values\n",
    "plt.plot(model_complete.history['acc'])\n",
    "plt.plot(model_complete.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Valid'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(model_complete.history['loss'])\n",
    "plt.plot(model_complete.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Valid'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate test generator to get model accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model.evaluate_generator(test_generator, steps=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict on test pictures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = new_model.predict_generator(test_generator, steps=10, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve dictionnary of classes of test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'Rhodesian_ridgeback',\n",
       " 1: 'Scotch_terrier',\n",
       " 2: 'French_bulldog',\n",
       " 3: 'Great_Dane',\n",
       " 4: 'Eskimo_dog'}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_map = dict((v, k.split(\"-\")[1]) for k, v in test_generator.class_indices.items())\n",
    "test_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get max proba for each picture (most probable class i.e. dog's breed)\n",
    "\n",
    "### The following accuracy is not to be trusted as representative of the model because we don't know if the model is predicting on test pictures in the same order as these pictures are ordered in the test directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# get max proba\n",
    "max_preds = pred.argmax(axis=1)\n",
    "print(max_preds)\n",
    "# convert to dataframe\n",
    "pred_df = pd.DataFrame(max_preds, columns=['pred_label'])\n",
    "pred_df['pred_name'] = pred_df.pred_label.apply(lambda x: test_map[x])\n",
    "pred_df['true_name'] = test_pictures_breeds\n",
    "pred_df['true_id'] = pred_df.true_name.apply(lambda x: reverse_breed_dict[x])\n",
    "\n",
    "# pred_df['true_id'] = target_names\n",
    "# pred_df['true_name'] = pred_df.true_id.apply(lambda x: breed_dict[x])\n",
    "# pred_df['true_label'] = pred_df.true_name.apply(lambda x: label_breed_dict[x])\n",
    "pred_df['true_label'] = pred_df.true_name.apply(lambda x: subfold_enc.transform([x])[0])\n",
    "pred_df['accurate'] = pd.Series([True if predict == truth else False for predict, truth in pred_df.loc[:, ['pred_label', 'true_label']].values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_label</th>\n",
       "      <th>pred_name</th>\n",
       "      <th>true_name</th>\n",
       "      <th>true_id</th>\n",
       "      <th>true_label</th>\n",
       "      <th>accurate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Rhodesian_ridgeback</td>\n",
       "      <td>Rhodesian_ridgeback</td>\n",
       "      <td>n02087394</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Rhodesian_ridgeback</td>\n",
       "      <td>Rhodesian_ridgeback</td>\n",
       "      <td>n02087394</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Rhodesian_ridgeback</td>\n",
       "      <td>Scotch_terrier</td>\n",
       "      <td>n02097298</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Rhodesian_ridgeback</td>\n",
       "      <td>Scotch_terrier</td>\n",
       "      <td>n02097298</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Rhodesian_ridgeback</td>\n",
       "      <td>French_bulldog</td>\n",
       "      <td>n02108915</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>Rhodesian_ridgeback</td>\n",
       "      <td>French_bulldog</td>\n",
       "      <td>n02108915</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>Rhodesian_ridgeback</td>\n",
       "      <td>Great_Dane</td>\n",
       "      <td>n02109047</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>Rhodesian_ridgeback</td>\n",
       "      <td>Great_Dane</td>\n",
       "      <td>n02109047</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>Rhodesian_ridgeback</td>\n",
       "      <td>Eskimo_dog</td>\n",
       "      <td>n02109961</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>Rhodesian_ridgeback</td>\n",
       "      <td>Eskimo_dog</td>\n",
       "      <td>n02109961</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pred_label            pred_name            true_name    true_id  \\\n",
       "0           0  Rhodesian_ridgeback  Rhodesian_ridgeback  n02087394   \n",
       "1           0  Rhodesian_ridgeback  Rhodesian_ridgeback  n02087394   \n",
       "2           0  Rhodesian_ridgeback       Scotch_terrier  n02097298   \n",
       "3           0  Rhodesian_ridgeback       Scotch_terrier  n02097298   \n",
       "4           0  Rhodesian_ridgeback       French_bulldog  n02108915   \n",
       "5           0  Rhodesian_ridgeback       French_bulldog  n02108915   \n",
       "6           0  Rhodesian_ridgeback           Great_Dane  n02109047   \n",
       "7           0  Rhodesian_ridgeback           Great_Dane  n02109047   \n",
       "8           0  Rhodesian_ridgeback           Eskimo_dog  n02109961   \n",
       "9           0  Rhodesian_ridgeback           Eskimo_dog  n02109961   \n",
       "\n",
       "   true_label  accurate  \n",
       "0           3     False  \n",
       "1           3     False  \n",
       "2           4     False  \n",
       "3           4     False  \n",
       "4           1     False  \n",
       "5           1     False  \n",
       "6           2     False  \n",
       "7           2     False  \n",
       "8           0      True  \n",
       "9           0      True  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(pred_df.true_label, pred_df.pred_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train dummy classifier for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20142000000000002"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_testing = pred_df.true_label.values\n",
    "mean_rand = []\n",
    "for i in range(5000):\n",
    "    random_pred = []\n",
    "    for target in target_testing :\n",
    "        random_pred.append(np.random.randint(target_testing.min(), target_testing.max()))\n",
    "    random_pred = np.array(random_pred)\n",
    "    mean_rand.append(np.equal(target_testing.reshape(-1), random_pred).sum() / len(target_testing))\n",
    "mean(mean_rand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
