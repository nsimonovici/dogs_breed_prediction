{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import os\n",
    "import pandas as pd\n",
    "from shutil import copyfile, rmtree\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from keras.layers import Flatten, Dense, Dropout, BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras.preprocessing.image import load_img, img_to_array, ImageDataGenerator\n",
    "from keras import optimizers\n",
    "import scipy.io\n",
    "from PIL import Image\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dynamic_std_print(string_to_print):\n",
    "    \"\"\"\n",
    "    Printing string on standard output and refreshing output line\n",
    "    \"\"\"\n",
    "    sys.stdout.write('\\r')\n",
    "    sys.stdout.write(string_to_print)\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Get data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gather our files paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get local path\n",
    "local_path = os.getcwd()\n",
    "pictures_path = local_path + '/data/images/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List images folders\n",
    "breeds_folders = [local_path + \"/data/images/\" + file_name for file_name in os.listdir(local_path + \"/data/images\") if os.path.isdir(local_path + \"/data/images/\" + file_name)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List breeds id and name\n",
    "breeds_id = [breed_path.split(\"/\")[-1].split(\"-\")[0] for breed_path in breeds_folders]\n",
    "breeds_name = [\"-\".join(breed_path.split(\"/\")[-1].split(\"-\")[1:]) for breed_path in breeds_folders]\n",
    "breed_dict = dict(zip(breeds_id, breeds_name))\n",
    "n_breeds = len(breeds_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use train and test sets provided with data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mat = scipy.io.loadmat(local_path + '/data/lists/train_list.mat')\n",
    "test_mat = scipy.io.loadmat(local_path + '/data/lists/test_list.mat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert matlab matrix to pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# For train set\n",
    "train_df = pd.DataFrame(train_mat['labels'], columns=['label'])\n",
    "train_df['file'] = [str(file_name[0].tolist()[0]) for file_name in train_mat['file_list']]\n",
    "train_df['breed_id'] = train_df.file.apply(lambda x: x.split(\"/\")[0].split(\"-\")[0])\n",
    "train_df['breed_name'] = train_df.breed_id.apply(lambda x: breed_dict[x])\n",
    "\n",
    "# For test set\n",
    "test_df = pd.DataFrame(test_mat['labels'], columns=['label'])\n",
    "test_df['file'] = [str(file_name[0].tolist()[0]) for file_name in test_mat['file_list']]\n",
    "test_df['breed_id'] = test_df.file.apply(lambda x: x.split(\"/\")[0].split(\"-\")[0])\n",
    "test_df['breed_name'] = test_df.breed_id.apply(lambda x: breed_dict[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get label-names dict\n",
    "breed_labels_df = train_df.loc[:, ['label', 'breed_name']].drop_duplicates()\n",
    "breed_label_dict = dict(zip(breed_labels_df.label.values, breed_labels_df.breed_name.values))\n",
    "label_breed_dict = dict([[v,k] for k,v in breed_label_dict.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>file</th>\n",
       "      <th>breed_id</th>\n",
       "      <th>breed_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8446</th>\n",
       "      <td>85</td>\n",
       "      <td>n02106662-German_shepherd/n02106662_1637.jpg</td>\n",
       "      <td>n02106662</td>\n",
       "      <td>German_shepherd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2203</th>\n",
       "      <td>23</td>\n",
       "      <td>n02091244-Ibizan_hound/n02091244_1917.jpg</td>\n",
       "      <td>n02091244</td>\n",
       "      <td>Ibizan_hound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8324</th>\n",
       "      <td>84</td>\n",
       "      <td>n02106550-Rottweiler/n02106550_12760.jpg</td>\n",
       "      <td>n02106550</td>\n",
       "      <td>Rottweiler</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5014</th>\n",
       "      <td>51</td>\n",
       "      <td>n02097658-silky_terrier/n02097658_4363.jpg</td>\n",
       "      <td>n02097658</td>\n",
       "      <td>silky_terrier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3153</th>\n",
       "      <td>32</td>\n",
       "      <td>n02093754-Border_terrier/n02093754_175.jpg</td>\n",
       "      <td>n02093754</td>\n",
       "      <td>Border_terrier</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                          file   breed_id  \\\n",
       "8446     85  n02106662-German_shepherd/n02106662_1637.jpg  n02106662   \n",
       "2203     23     n02091244-Ibizan_hound/n02091244_1917.jpg  n02091244   \n",
       "8324     84      n02106550-Rottweiler/n02106550_12760.jpg  n02106550   \n",
       "5014     51    n02097658-silky_terrier/n02097658_4363.jpg  n02097658   \n",
       "3153     32    n02093754-Border_terrier/n02093754_175.jpg  n02093754   \n",
       "\n",
       "           breed_name  \n",
       "8446  German_shepherd  \n",
       "2203     Ibizan_hound  \n",
       "8324       Rottweiler  \n",
       "5014    silky_terrier  \n",
       "3153   Border_terrier  "
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy files to train and test folders for CNN training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Copy train files to train folder\n",
    "# for file in train_df.file.values:\n",
    "#     folder = file.split(\"/\")[0]\n",
    "#     file_name = file.split(\"/\")[-1]\n",
    "#     if not os.path.exists(local_path + '\\\\data\\\\train\\\\' + folder):\n",
    "#         os.mkdir(local_path + '\\\\data\\\\train\\\\' + folder)\n",
    "#         dynamic_std_print(\"Creating folder {}                  \".format(folder))\n",
    "#     copyfile(pictures_path + file, local_path + '\\\\data\\\\train\\\\' + folder + '\\\\' + file_name)\n",
    "    \n",
    "# # Copy test files to test folder\n",
    "# for file in test_df.file.values:\n",
    "#     folder = file.split(\"/\")[0]\n",
    "#     file_name = file.split(\"/\")[-1]\n",
    "#     if not os.path.exists(local_path + '\\\\data\\\\test\\\\' + folder):\n",
    "#         os.mkdir(local_path + '\\\\data\\\\test\\\\' + folder)\n",
    "#         dynamic_std_print(\"Creating folder {}                  \".format(folder))\n",
    "#     copyfile(pictures_path + file, local_path + '\\\\data\\\\test\\\\' + folder + '\\\\' + file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy files to small train and test folders for CNN training (few files for debuging purposes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WinError 32] Le processus ne peut pas accéder au fichier car ce fichier est utilisé par un autre processus: 'D:\\\\FORMATIONS\\\\OCLR\\\\0-PARCOURS-DATA_SCIENTIST\\\\6-Realiser_Des_Indexations_Automatiques_d_Images\\\\data\\\\debuging\\\\test\\\\test_folder\\\\n02091467_3942.jpg'\n"
     ]
    }
   ],
   "source": [
    "# Remove folders content\n",
    "folders = [local_path + '\\\\data\\\\debuging\\\\train\\\\',\n",
    "           local_path + '\\\\data\\\\debuging\\\\test\\\\test_folder',\n",
    "           local_path + '\\\\data\\\\debuging\\\\valid\\\\']\n",
    "for folder in folders:\n",
    "    for the_file in os.listdir(folder):\n",
    "        file_path = os.path.join(folder, the_file)\n",
    "        try:\n",
    "            if os.path.isfile(file_path):\n",
    "                os.unlink(file_path)\n",
    "            elif os.path.isdir(file_path):\n",
    "                rmtree(file_path)\n",
    "        except Exception as e:\n",
    "            print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating folder n02116738-African_hunting_dog                                        "
     ]
    }
   ],
   "source": [
    "# Copy train and valid  files to train and valid folders\n",
    "# Get n pic for each label\n",
    "n_train = 10\n",
    "n_valid = 2\n",
    "n_test = 2\n",
    "\n",
    "for label in train_df.label.unique():\n",
    "    label_df = train_df[train_df.label == label].sample(n_train + n_valid, random_state=0)\n",
    "    \n",
    "    # Copy training files\n",
    "    for file in label_df.file.values[:n_train]:\n",
    "        folder = file.split(\"/\")[0]\n",
    "        file_name = file.split(\"/\")[-1]\n",
    "        if not os.path.exists(local_path + '\\\\data\\\\debuging\\\\train\\\\' + folder):\n",
    "            os.mkdir(local_path + '\\\\data\\\\debuging\\\\train\\\\' + folder)\n",
    "            dynamic_std_print(\"Creating folder {}                             \".format(folder))\n",
    "        copyfile(pictures_path + file, local_path + '\\\\data\\\\debuging\\\\train\\\\' + folder + '\\\\' + file_name)\n",
    "        \n",
    "    # Copy validation files        \n",
    "    for file in label_df.file.values[n_train:]:\n",
    "        folder = file.split(\"/\")[0]\n",
    "        file_name = file.split(\"/\")[-1]\n",
    "        if not os.path.exists(local_path + '\\\\data\\\\debuging\\\\valid\\\\' + folder):\n",
    "            os.mkdir(local_path + '\\\\data\\\\debuging\\\\valid\\\\' + folder)\n",
    "            dynamic_std_print(\"Creating folder {}                             \".format(folder))\n",
    "        copyfile(pictures_path + file, local_path + '\\\\data\\\\debuging\\\\valid\\\\' + folder + '\\\\' + file_name)\n",
    "    \n",
    "# Copy test files to test folder\n",
    "# Get m pic for each label\n",
    "target_names = []\n",
    "for label in train_df.label.unique():\n",
    "    label_df = test_df[test_df.label == label].sample(n_test, random_state=0)\n",
    "    for file in label_df.file.values:\n",
    "        folder = file.split(\"/\")[0]\n",
    "        file_name = file.split(\"/\")[-1]\n",
    "        file_breed = file_name.split(\"_\")[0]\n",
    "        target_names.append(file_breed)\n",
    "        copyfile(pictures_path + file, local_path + '\\\\data\\\\debuging\\\\test\\\\test_folder\\\\' + file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Modify Conventional Neural Network for Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use Keras VGG-16 CNN already trained on ImageNet database in order to predict our dogs breeds.\n",
    "\n",
    "Steps are as follow :\n",
    "- 1) Call the pre-trained VGG-16 CNN\n",
    "- 2) Apply partial fine-tuning because we don't have much data (20e3) and they are dogs only, unlike ImageNet database\n",
    "- 3) Run modified model for dogs classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare pictures batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1200 images belonging to 120 classes.\n"
     ]
    }
   ],
   "source": [
    "train_batch_size = 20\n",
    "# Initialise data generator\n",
    "train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "# Fit generator from train folder. Folder must contains one sub-directory by class\n",
    "train_generator = train_datagen.flow_from_directory(local_path + '/data/debuging/train',\n",
    "                                                    target_size=(224,224),\n",
    "                                                    color_mode='rgb',\n",
    "                                                    batch_size=train_batch_size,\n",
    "                                                    class_mode='categorical',\n",
    "                                                    shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 240 images belonging to 120 classes.\n"
     ]
    }
   ],
   "source": [
    "valid_batch_size = 20\n",
    "# Initialise data generator\n",
    "valid_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "# Fit generator from train folder. Folder must contains one sub-directory by class\n",
    "valid_generator = valid_datagen.flow_from_directory(local_path + '/data/debuging/valid',\n",
    "                                                    target_size=(224,224),\n",
    "                                                    color_mode='rgb',\n",
    "                                                    batch_size=valid_batch_size,\n",
    "                                                    class_mode='categorical',\n",
    "                                                    shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 240 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "test_batch_size = 20\n",
    "# Initialise data generator\n",
    "test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "# Fit generator from train folder. Folder must contains one sub-directory by class\n",
    "test_generator = test_datagen.flow_from_directory(local_path + '/data/debuging/test',\n",
    "                                                  target_size=(224,224),\n",
    "                                                  color_mode='rgb',\n",
    "                                                  batch_size=test_batch_size,\n",
    "                                                  class_mode='categorical',\n",
    "                                                  shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count=1\n",
    "# for item in test_generator:\n",
    "#     print(count)\n",
    "# #     save_test_item = item\n",
    "# #     break\n",
    "#     count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_test_item[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prep model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Charger VGG-16 pré-entraîné sur ImageNet et sans les couches fully-connected\n",
    "model = VGG16(weights=\"imagenet\", include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Récupérer la sortie de ce réseau\n",
    "x = model.output\n",
    "\n",
    "# ???\n",
    "x = model.output\n",
    "x = Flatten()(x)\n",
    "x = Dropout(0.4)(x)\n",
    "# let's add two fully-connected layer\n",
    "x = Dense(2048, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.4)(x)\n",
    "x = Dense(2048, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.2)(x)\n",
    "\n",
    "# Ajouter la nouvelle couche fully-connected pour la classification à 120 classes\n",
    "predictions = Dense(120, activation='softmax')(x)\n",
    "\n",
    "# Définir le nouveau modèle\n",
    "new_model = Model(inputs=model.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ne pas entraîner les 5 premières couches (les plus basses) \n",
    "for layer in new_model.layers[:5]:\n",
    "   layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiler le modèle \n",
    "new_model.compile(loss=\"categorical_crossentropy\", optimizer=optimizers.SGD(lr=0.0001, momentum=0.9), metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's in our model so far ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2048)              51382272  \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 2048)              8192      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2048)              4196352   \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 2048)              8192      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 120)               245880    \n",
      "=================================================================\n",
      "Total params: 70,555,576\n",
      "Trainable params: 70,434,808\n",
      "Non-trainable params: 120,768\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "60/60 [==============================] - 737s 12s/step - loss: 5.7893 - acc: 0.0092 - val_loss: 5.1261 - val_acc: 0.0083\n",
      "Epoch 2/3\n",
      "60/60 [==============================] - 737s 12s/step - loss: 5.6708 - acc: 0.0125 - val_loss: 9.1359 - val_acc: 0.0167\n",
      "Epoch 3/3\n",
      "60/60 [==============================] - 745s 12s/step - loss: 5.8841 - acc: 0.0125 - val_loss: 5.8571 - val_acc: 0.0125\n"
     ]
    }
   ],
   "source": [
    "#Entraîner sur les données d'entraînement (X_train, y_train)\n",
    "model_complete = new_model.fit_generator(train_generator,\n",
    "#                                          steps_per_epoch=2000,\n",
    "                                         epochs=3,\n",
    "                                         validation_data=valid_generator,\n",
    "#                                          validation_steps=800,\n",
    "                                         verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict on test pictures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 54s 5s/step\n"
     ]
    }
   ],
   "source": [
    "pred = new_model.predict_generator(test_generator, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get max proba for each picture (most probable class i.e. dog's breed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get max proba\n",
    "max_preds = pred.argmax(axis=1)\n",
    "# convert to dataframe\n",
    "pred_df = pd.DataFrame(max_preds, columns=['pred_label'])\n",
    "pred_df['pred_name'] = pred_df.pred_label.apply(lambda x: breed_label_dict[x])\n",
    "pred_df['true_id'] = target_names\n",
    "pred_df['true_name'] = pred_df.true_id.apply(lambda x: breed_dict[x])\n",
    "pred_df['true_label'] = pred_df.true_name.apply(lambda x: label_breed_dict[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_label</th>\n",
       "      <th>pred_name</th>\n",
       "      <th>true_id</th>\n",
       "      <th>true_name</th>\n",
       "      <th>true_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1</td>\n",
       "      <td>Chihuahua</td>\n",
       "      <td>n02091467</td>\n",
       "      <td>Norwegian_elkhound</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>29</td>\n",
       "      <td>Staffordshire_bullterrier</td>\n",
       "      <td>n02098286</td>\n",
       "      <td>West_Highland_white_terrier</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>103</td>\n",
       "      <td>pug</td>\n",
       "      <td>n02112018</td>\n",
       "      <td>Pomeranian</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>98</td>\n",
       "      <td>Eskimo_dog</td>\n",
       "      <td>n02095570</td>\n",
       "      <td>Lakeland_terrier</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>103</td>\n",
       "      <td>pug</td>\n",
       "      <td>n02108089</td>\n",
       "      <td>boxer</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     pred_label                  pred_name    true_id  \\\n",
       "46            1                  Chihuahua  n02091467   \n",
       "104          29  Staffordshire_bullterrier  n02098286   \n",
       "214         103                        pug  n02112018   \n",
       "76           98                 Eskimo_dog  n02095570   \n",
       "183         103                        pug  n02108089   \n",
       "\n",
       "                       true_name  true_label  \n",
       "46            Norwegian_elkhound          24  \n",
       "104  West_Highland_white_terrier          53  \n",
       "214                   Pomeranian         108  \n",
       "76              Lakeland_terrier          39  \n",
       "183                        boxer          92  "
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0125"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(pred_df.true_label, pred_df.pred_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_pic = test_df.sample(1)\n",
    "# pic_path = pictures_path + test_pic.file.values\n",
    "\n",
    "# img = load_img(pic_path.tolist()[0], target_size=(224, 224))  # Charger l'image\n",
    "# img = img_to_array(img)  # Convertir en tableau numpy\n",
    "# img = img.reshape((1, img.shape[0], img.shape[1], img.shape[2]))  # Créer la collection d'images (un seul échantillon)\n",
    "# img = preprocess_input(img)  # Prétraiter l'image comme le veut VGG-16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = new_model.predict(img)  # Prédir la classe de l'image (parmi les 1000 classes d'ImageNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_complete = new_model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
